# ğŸï¸ Racedemia : Learning Style-Conditioned Race Driving Policies via Diffusion in Online Reinforcement Learning
## ğŸ“‚ Repository Structure
```
diffusion_soft_actor_critic/
â”œâ”€â”€ soft_dac/ : implementation of the soft diffusion actor critic policy
â”‚    â”œâ”€â”€ diffusion/
â”‚        â”œâ”€â”€ actor_diffusion.py : diffusion policy
â”‚        â”œâ”€â”€ scheduler.py       : noise scheduler (linear_beta_scheduler, cosine_beta_scheduler, vp_beta_scheduler)
â”‚    â”œâ”€â”€ networks/
â”‚        â”œâ”€â”€ critic.py          : Q1, Q1 network as the SAC
â”‚        â”œâ”€â”€ module.py          : Time embedding layer, etc
â”œâ”€â”€ notebooks/
â”œâ”€â”€ policy/ : implementation of the default SAC and Multi-Style conditioned SAC
â”‚    â”œâ”€â”€ main.py
â”‚    â”œâ”€â”€ model.py
â”‚    â”œâ”€â”€ replay_memory.py
â”œâ”€â”€ sota/
â”‚    â”œâ”€â”€ DACER/
â”‚    â”œâ”€â”€ DIPO/
â”‚    â”œâ”€â”€ DPPO/
â”‚    â”œâ”€â”€ QVPO/
â”‚    â”œâ”€â”€ SQM/
â””â”€â”€ ReadMe.md
```
## âš™ï¸ Implementation Details
### 
